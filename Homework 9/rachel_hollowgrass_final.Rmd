---
title: "COMPSCIX 415.2 Homework 9/Final"
author: "Rachel Hollowgrass"
date: "4/3/2018"
output:
 html_document:
  self_contained: true
---

```{r, warning = FALSE, message = FALSE}
# load packages
library(tidyverse)
library(modelr)
library(rpart)
library(partykit)
library(randomForest)
```


### Bootstrapping (10 points)  

<ol start="1">
  <li>Follow these steps:</li>
</ol>

<ul>
  <li>Load the train.csv dataset into R.</li>
  <li>Convert all <code>character</code> columns into unordered <code>factors</code>.</li>
  <li>Convert the <code>Survived</code> column into an unordered factor because it is loaded as an integer by default.</li>
  <li>Take a <code>glimpse</code> of your data to confirm that all of the columns were converted correctly.</li>
</ul>

```{r}
file_path <- '../data/homework9/train.csv'
train <- read_csv(file_path)
train
```


```{r}
# Character vars:
# Name = col_character(),
# Sex = col_character(),
# Ticket = col_character(),
# Cabin = col_character(),
# Embarked = col_character()

# •• Look for a function that creates factors for multiple columns at once. ••
# Not factoring Name, Ticket or Cabin because each instance is unique or almost unique and would not factor well.
# Factors are unordered by default, so no need to add ', ordered = FALSE' after the vector assignment.

# Survived is not a continous variable, so make a factor for it.
train <- train %>% mutate(Survived = 
  factor(case_when(
                  Survived == 1 ~ 'True',
                  Survived == 0 ~ 'False'
                  ),
            levels = c('True', 'False')
         )
  )

# Sex is also not a continous variable, so make a factor for it.
train <- train %>% mutate(Sex = 
  factor(case_when(
                  Sex == "male" ~ 'Man',
                  Sex == "female" ~ 'Woman'
               ),
            levels = c('Man', 'Woman')
         )
  )

# Pclass is also not a continous variable, so make a factor for it.
train <- train %>% mutate(Pclass = 
  factor(case_when(
                  Pclass == 1 ~ 'First',
                  Pclass == 2 ~ 'Second',
                  Pclass == 3 ~ 'Third'
                  ),
            levels = c('First', 'Second', 'Third')
         )
  )

# Embarked is also not a continous variable, so make a factor for it.
# S = Southampton, England
# C = Cherbourg, France
# Q = Queenstown, Ireland
# Never arrived at New York

train <- train %>% mutate(Embarked = 
  factor(case_when(
                  Embarked == "C" ~ 'Cherbourg',
                  Embarked == "Q" ~ 'Queenstown',
                  Embarked == "S" ~ 'Southampton'
                  ),
            levels = c('Southampton', 'Cherbourg', 'Queenstown')
         )
  )

glimpse(train)
```

We will use this same dataset for this entire assignment.

<ol start="2">
  <li>Use the code below to take 100 bootstrap samples of your data. Confirm that the result is a <code>tibble</code> with a <code>list</code> column of <code>resample</code> objects - each <code>resample</code> object is a bootstrap sample of the titanic dataset.</li>
</ol>

_I've displayed <code>titanic_boot</code>, which confirms that the result has a column of 100 <code>resample</code> objects._

```{r}
# These two lines were already called in the first code snippet.
# library(tidyverse)
# library(modelr)

titanic_boot <- bootstrap(data = train, n = 100)

# Displaying titanic_boot confirms that the result has a column of 100 <code>resample</code> objects
titanic_boot
```

<ol start="3">
  <li>Confirm that some of your bootstrap samples are in fact bootstrap samples (meaning they should have some rows that are repeated). You can use the <code>n_distinct()</code> function from <code>dplyr</code> to see that your samples have different numbers of unique rows. Use the code below to help you extract some of the <code>resample</code> objects from the <code>strap</code> column (which is an R <code>list</code>), convert them to tibbles, and then count distinct rows. Use the code below, no changes necessary.</li>
</ol>

```{r}
# since the strap column of titanic_boot is a list, we can
# extract the resampled data using the double brackets [[]],
# and just pick out a few of them to compare the number of
# distinct rows
as.tibble(titanic_boot$strap[[1]]) %>% n_distinct()
as.tibble(titanic_boot$strap[[2]]) %>% n_distinct()
as.tibble(titanic_boot$strap[[3]]) %>% n_distinct()
```

<ol start="4">
  <li>Now, let’s demonstrate the Central Limit Theorem using the <code>Age</code> column. We’ll iterate through all 100 bootstrap samples, take the mean of <code>Age</code>, and collect the results.</li>
</ol>

<ul>
  <li>We will define our own function to pull out the mean of <code>Age</code> from each bootstrap sample and</li>
  <li>create our own <code>for</code> loop to iterate through.</li>
</ul>

Use the code below and fill in the blanks.  

```{r}
age_mean <- function(input_data) {
  data <- as.tibble(input_data) # convert input data set to a tibble
  mean_age <- mean(data$Age, na.rm = TRUE) # take the mean of Age, remove NAs
  return(mean_age) # return the mean value of Age from data
}


# loop through the 100 bootstrap samples and use the age_mean()
# function
all_means <- rep(NA, 100)

# start the loop
for(i in 1:100) {
  all_means[i] <- age_mean(titanic_boot$strap[[i]])
}

# take a look at some of the means you calculated from your samples
head(all_means)

# convert to a tibble so we can use if for plotting
all_means <- tibble(all_means = all_means)
all_means
```

<ol start="5">
  <li>Plot a histogram of <code>all_means</code>.</li>
</ol>

```{r}
ggplot(all_means) +
  geom_histogram(aes(all_means), binwidth=0.2) + 
  ggtitle('Histogram of all_means')
```

<ol start="6">
  <li>Find the standard error of the sample mean of <code>Age</code> using your boostrap sample means. Compare the empirical standard error to the theoretical standard error.</li>
</ol>

Recall that the theoretical standard error is given by:  

![](../images/standard_error.png)  

where <em>σ</em> is the standard deviation of <code>Age</code> and <em>n</em> is the size of our sample.  

_"the standard error of a sampling distribution is the standard deviation of the sampling distribution"_

```{r}
# empirical standard error
se_empirical <- sd(all_means$all_means) / count(all_means)
paste("Empirical standard error:", toString(se_empirical))

# theoretical standard error
se_theoretical <- sd(train$Age, na.rm=TRUE) / count(train)
paste("Theoretical standard error:", toString(se_theoretical))

"As expected, the empirical standard error is smaller than the theoretical standard error."

```

### Random forest (10 points)  

On the last homework, we fit a decision tree to the Titanic data set to predict the probability of survival given the features. This week we’ll use the random forest and compare our results to the decision tree.  

<ol start="1">
  <li>Randomly split your data into training and testing using the code below so that we all have the same sets.</li>
</ol>

```{r}

file_path <- '../data/homework9/train.csv'
train <- read_csv(file_path)

train <- train %>% mutate(Survived = 
  factor(case_when(
                  Survived == 1 ~ 'True',
                  Survived == 0 ~ 'False'
                  ),
            levels = c('True', 'False')
         )
  )

train <- train %>% mutate(Sex = 
  factor(case_when(
                  Sex == "male" ~ 'Man',
                  Sex == "female" ~ 'Woman'
               ),
            levels = c('Man', 'Woman')
         )
  )

train <- train %>% mutate(Pclass = 
  factor(case_when(
                  Pclass == 1 ~ 'First',
                  Pclass == 2 ~ 'Second',
                  Pclass == 3 ~ 'Third'
                  ),
            levels = c('First', 'Second', 'Third')
         )
  )

train <- train %>% mutate(Embarked = 
  factor(case_when(
                  Embarked == "C" ~ 'Cherbourg',
                  Embarked == "Q" ~ 'Queenstown',
                  Embarked == "S" ~ 'Southampton'
                  ),
            levels = c('Southampton', 'Cherbourg', 'Queenstown')
         )
  )

# set.seed(987)
# model_data <- resample_partition(train, c(test = 0.3, train = 0.7))
# train_set <- as.tibble(model_data$PassengerId)
# test_set <- as.tibble(model_data$PassengerId)

set.seed(29283)
train_set <- train %>% sample_frac(.7)
test_set <- train %>% filter(!(train$PassengerId %in% train_set$PassengerId))

```

<ol start="2">
  <li>Fit a decision tree to <code>train_set</code> using the <code>rpart</code> package, and using <code>Pclass</code>, <code>Sex</code>, <code>Age</code>, <code>SibSp</code>, <code>Parch</code>, <code>Fare</code>, <code>Embarked</code> as the features.</li>
</ol>

<ul>
  <li>Plot the tree using the <code>partykit</code> package.</li>
  <li>What do you notice about this tree compared to the one from last week which only contained three features?  
  _In both the old and the new trees, Sex and Pclass are still the strongest determinants of survival. For men, age emerges are more important than Fare. For women, Fare is more important than Age._</li>
</ul>

```{r}

tree_mod_old <- rpart(Survived ~ Pclass + Sex + Fare, data = train_set)
tree_mod <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked, data = train_set)

plot(as.party(tree_mod_old))
plot(as.party(tree_mod))
```

